{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7abacd74-0505-477d-acaa-deae9300a0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Dorothy\n",
      "[nltk_data]     Wekesa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt') #Unsupervised trained tokenizer model for sentence segmentation\n",
    "nltk.download('wordnet') #Lexical database for word sense, meaning \n",
    "nltk.download('omw-1.4')#WordNet extension for multilingual translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d00b6af-ac4d-4bda-a139-3751cd8544e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Dorothy\n",
      "[nltk_data]     Wekesa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords') #List of common non-informative words i.e is, the etc\n",
    "nltk.download('averaged_perceptron_tagger') #Taging words as nouns, verbs etc\n",
    "nltk.download('maxent_ne_chunker') #Named entity recognition for proper nauns, places, organizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c40d9d1a-0783-4c96-99b7-ff240d1dd80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to C:\\Users\\Dorothy\n",
      "[nltk_data]     Wekesa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words') #Check if word exists/ is valid - True or False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a256e1-37d7-444e-936e-fde81a17bc35",
   "metadata": {},
   "source": [
    "PROCEDURE\n",
    "Library and toolkit download\n",
    "Segmentation\n",
    "Tokenization\n",
    "Stop word removal\n",
    "Stemming n lemmatization\n",
    "Speech tagging\n",
    "Name entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f0e7a754-293d-43a1-a047-f93e58179718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I wanna see how this plays out, so am using: semi-colons; commas, and colons. you can only imply     end of sentence by use of a fullstop. This is not good - not for a lack of trying though but for starting trainees in the English language. '"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" I wanna see how this plays out, so am using: semi-colons; commas, and colons. you can only imply     end of sentence by use of a fullstop. This is not good - not for a lack of trying though but for starting trainees in the English language. \"\n",
    "text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "380e2152-ca8b-4ad1-a0bf-d9b07d334b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Dorothy\n",
      "[nltk_data]     Wekesa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' I wanna see how this plays out, so am using: semi-colons; commas, and colons.',\n",
       " 'you can only imply     end of sentence by use of a fullstop.',\n",
       " 'This is not good - not for a lack of trying though but for starting trainees in the English language.']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TOKENIZE. Divide paragraph text into sentences\n",
    "nltk.download('punkt_tab') # Tokenizer model stored in tab files\n",
    "from nltk.tokenize import sent_tokenize\n",
    "split_sent = sent_tokenize(text)\n",
    "split_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47c54882-a7ba-46bf-89bf-0c4702966e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This is not good - not for a lack of trying though but for 'procrastination' in English terms.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_sent[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c7a72883-fc95-4242-8b01-d0f3ad2aef2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is not good   not for a lack of trying though but for starting trainees in the English language '"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove punctuation\n",
    "import re \n",
    "text = re.sub(r\"[^a-zA-Z0-9]\", \" \", split_sent[2]) # Removes anything not a to z, 0 to 9, space or A to Z\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5d674914-69e0-4c8a-b903-fcc86e4c70f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'not', 'good', 'not', 'for', 'a', 'lack', 'of', 'trying', 'though', 'but', 'for', 'starting', 'trainees', 'in', 'the', 'English', 'language']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "words=word_tokenize(text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b4849aa-d6c3-4c98-998d-172d0adfadd5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arabic',\n",
       " 'azerbaijani',\n",
       " 'basque',\n",
       " 'bengali',\n",
       " 'catalan',\n",
       " 'chinese',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'hebrew',\n",
       " 'hinglish',\n",
       " 'hungarian',\n",
       " 'indonesian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'slovene',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'tajik',\n",
       " 'turkish']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.fileids() # Display nltk language library for stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3ffda689-ed94-4e3d-b66f-1c5b8316adf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'good', 'lack', 'trying', 'though', 'starting', 'trainees', 'English', 'language']\n"
     ]
    }
   ],
   "source": [
    "#REMOVE STOPWORDS\n",
    "from nltk.corpus import stopwords\n",
    "theewords = [w for w in words if w not in  stopwords.words(\"english\")]\n",
    "print (theewords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1785ab0b-c847-4adb-9f06-a565d4fcddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEMMATIZE and STEM\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "200c8c30-d3ca-4646-a6cb-06e8fb092ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'good', 'lack', 'trying', 'though', 'starting', 'trainee', 'English', 'language']\n"
     ]
    }
   ],
   "source": [
    "lmtzd = [WordNetLemmatizer().lemmatize(w) for w in theewords] #finds root of word present in dictionary\n",
    "print(lmtzd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "12640fa4-4ae6-498d-add9-ecad88afb1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thi', 'good', 'lack', 'tri', 'though', 'start', 'traine', 'english', 'languag']\n"
     ]
    }
   ],
   "source": [
    "stmd = [PorterStemmer().stem(w) for w in theewords] #finds root of word. For faster processing\n",
    "print(stmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4c9e0c84-27f5-454d-bdcf-d78368a087f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Dorothy Wekesa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('This', 'DT'),\n",
       " ('good', 'JJ'),\n",
       " ('lack', 'NN'),\n",
       " ('trying', 'VBG'),\n",
       " ('though', 'IN'),\n",
       " ('starting', 'VBG'),\n",
       " ('trainees', 'NNS'),\n",
       " ('English', 'JJ'),\n",
       " ('language', 'NN')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SPEECHTAGGING\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "from nltk import pos_tag\n",
    "pos_tag(theewords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fa7601a8-8b6c-4190-8f43-cfa92a4e256e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets_json to C:\\Users\\Dorothy\n",
      "[nltk_data]     Wekesa\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping help\\tagsets_json.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('tagsets_json')\n",
    "nltk.help.upenn_tagset() # Display meaning of speech tags abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f6e4c83b-403c-4014-a240-40f167fd693b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to C:\\Users\\Dorothy\n",
      "[nltk_data]     Wekesa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     C:\\Users\\Dorothy Wekesa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6d43e187-8427-4125-9a0a-025d95571565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  I/PRP\n",
      "  wan/VBP\n",
      "  na/TO\n",
      "  see/VB\n",
      "  how/WRB\n",
      "  this/DT\n",
      "  plays/VBZ\n",
      "  out/RP\n",
      "  ,/,\n",
      "  so/RB\n",
      "  am/VBP\n",
      "  using/VBG\n",
      "  :/:\n",
      "  semi-colons/NNS\n",
      "  ;/:\n",
      "  commas/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  colons/NNS\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "#NAME ENTITY RECOGNITION\n",
    "from nltk import ne_chunk\n",
    "recogo = ne_chunk(pos_tag(word_tokenize(split_sent[0])))\n",
    "print(recogo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e2b0ec-e6c4-4248-9e90-eb047dde9d23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
